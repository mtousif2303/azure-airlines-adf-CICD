# Azure Airlines Incremental CICD  Pipeline
Data Engineering Pipeline with DevOps Automation  
Tech Stack : ADLS, Azure Data Factory,GitHub, Azure DevOPS

## ğŸ“‹ Project Overview

An end-to-end data engineering solution for processing airline flight data with incremental loading, automated data transformations, and CI/CD deployment using Azure cloud services

---

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SOURCE DATA LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Azure Data Lake Storage Gen2 (ADLS)                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚  â”‚  landing-zn/       â”‚        â”‚  processed-data/   â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  - flights.csv     â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  - transformed     â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  - airports.csv    â”‚        â”‚    output          â”‚               â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TRANSFORMATION LAYER (ADF)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Azure Data Factory Pipeline: "airlinepipeline"                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚   â”‚
â”‚  â”‚  â”‚ GetMetadata     â”‚  Check if flights.csv exists                    â”‚   â”‚
â”‚  â”‚  â”‚ Activity        â”‚                                                 â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚   â”‚
â”‚  â”‚           â”‚                                                           â”‚   â”‚
â”‚  â”‚           â–¼                                                           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚   â”‚
â”‚  â”‚  â”‚ If Condition    â”‚                                                 â”‚   â”‚
â”‚  â”‚  â”‚ Activity        â”‚                                                 â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                 â”‚   â”‚
â”‚  â”‚       â”‚       â”‚                                                       â”‚   â”‚
â”‚  â”‚   TRUEâ”‚       â”‚FALSE                                                 â”‚   â”‚
â”‚  â”‚       â”‚       â”‚                                                       â”‚   â”‚
â”‚  â”‚       â–¼       â–¼                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚   â”‚
â”‚  â”‚  â”‚Execute â”‚  â”‚ Set Variable â”‚                                        â”‚   â”‚
â”‚  â”‚  â”‚DataFlowâ”‚  â”‚ (No Action)  â”‚                                        â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚   â”‚
â”‚  â”‚       â”‚                                                               â”‚   â”‚
â”‚  â”‚       â–¼                                                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚   â”‚
â”‚  â”‚  â”‚  Data Flow: "AirlineDataTransformation"      â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚                                               â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚  1. Read airports.csv (Airport Dimension)    â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚  2. Read flights.csv (Daily Flights)         â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚  3. JOIN on Origin Airport ID                â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚     â””â”€â–¶ Derive Departure Airport Details     â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚  4. JOIN on Destination Airport ID           â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚     â””â”€â–¶ Derive Arrival Airport Details       â”‚                   â”‚   â”‚
â”‚  â”‚  â”‚  5. Write to processed-data/                 â”‚                   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TARGET/ANALYTICS LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Azure Synapse Analytics                                             â”‚   â”‚
â”‚  â”‚  - Analytical queries                                                â”‚   â”‚
â”‚  â”‚  - Business intelligence                                             â”‚   â”‚
â”‚  â”‚  - Data visualization                                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CI/CD DEPLOYMENT LAYER                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  GitHub Repository                                                    â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ ARM Templates                                                    â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Pipeline Definitions                                            â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Configuration Files                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                                        â”‚
â”‚                     â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Azure DevOps                                                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚  â”‚   Build    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Release   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Deploy   â”‚             â”‚   â”‚
â”‚  â”‚  â”‚  Pipeline  â”‚      â”‚  Pipeline  â”‚      â”‚  to PROD   â”‚             â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Self-Hosted Agent Pool (Local Machine)                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---








## ğŸ¯ What Does This Pipeline Do?

### **Business Problem**
Airlines generate massive amounts of flight data daily. We need to:
- Process daily flight records incrementally
- Enrich flight data with airport information (city, state, airport names)
- Track departure and arrival delays
- Make data available for analytics and reporting

### **Pipeline Workflow**

1. **File Existence Check**
   - Pipeline checks if new daily flights file (`flights.csv`) exists in the landing zone
   - Uses GetMetadata activity to validate file availability

2. **Conditional Processing**
   - **If file exists (TRUE)**: Proceeds with data transformation
   - **If file doesn't exist (FALSE)**: Sets a variable and skips processing

3. **Data Transformation** (Mapping Data Flow)
   
   **Step 1: Load Source Data**
   - `airports.csv` - Dimension table with airport details (airport_id, city, state, name)
   - `flights.csv` - Daily flight facts (Carrier, OriginAirportID, DestAirportID, delays)

   **Step 2: Join on Departure Airport**
   - Joins flights with airports on `OriginAirportID = airport_id`
   - Derives departure airport details: city, state, airport name
   - Renames columns: `Depcity`, `Depstate`, `Depname`

   **Step 3: Join on Arrival Airport**
   - Joins result with airports again on `DestAirportID = airport_id`
   - Derives arrival airport details: city, state, airport name
   - Renames columns: `Arrcity`, `Arrstate`, `Arrname`

   **Step 4: Write Transformed Data**
   - Outputs enriched data to `processed-data/` folder
   - Truncates existing data before writing (full refresh within incremental load)

4. **Final Output Schema**
```
Carrier, DepDelay, ArrDelay, 
Depcity, Depstate, Depname,
Arrcity, Arrstate, Arrname
```

### **Example Transformation**

**Input (flights.csv):**
```
Carrier | OriginAirportID | DestAirportID | DepDelay | ArrDelay
UA      | 12478           | 14107         | 10       | 5
```

**Reference (airports.csv):**
```
airport_id | city          | state | name
12478      | New York      | NY    | JFK International
14107      | Los Angeles   | CA    | LAX International
```

**Output (processed):**
```
Carrier | DepDelay | ArrDelay | Depcity  | Depstate | Depname            | Arrcity     | Arrstate | Arrname
UA      | 10       | 5        | New York | NY       | JFK International  | Los Angeles | CA       | LAX International
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Source** | Azure Data Lake Storage Gen2 | Raw data storage (landing zone & processed data) |
| **Orchestration** | Azure Data Factory | Pipeline orchestration, data movement, transformations |
| **Transformation** | ADF Mapping Data Flows | ETL logic, joins, derived columns |
| **Analytics** | Azure Synapse Analytics | Data warehousing, querying, BI |
| **Monitoring** | Logic Apps | Alerts and notifications (optional) |
| **Version Control** | GitHub | Source code repository |
| **CI/CD** | Azure DevOps | Automated build and deployment |
| **Agent** | Self-Hosted Agent | Local machine agent for deployment |

---

## ğŸ“‚ Repository Structure

```
azure-airlines-incremental-pipeline/
â”‚
â”œâ”€â”€ arm-templates/
â”‚   â”œâ”€â”€ ARMTemplateForFactory.json              # Main ARM template
â”‚   â”œâ”€â”€ ARMTemplateParametersForFactory.json    # Parameters for DEV
â”‚   â”œâ”€â”€ ArmTemplate_master.json                 # Linked template master
â”‚   â”œâ”€â”€ ArmTemplateParameters_master.json       # Master parameters
â”‚   â””â”€â”€ ArmTemplate_0.json                      # Component template
â”‚
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ airlinepipeline.json                    # Pipeline definition
â”‚
â”œâ”€â”€ dataflows/
â”‚   â””â”€â”€ AirlineDataTransformation.json          # Data flow transformation logic
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ AirlineDimSource.json                   # Airport dimension dataset
â”‚   â”œâ”€â”€ DailyFlightsSource.json                 # Daily flights dataset
â”‚   â””â”€â”€ Processeddata.json                      # Output dataset
â”‚
â”œâ”€â”€ linkedservices/
â”‚   â””â”€â”€ AzureDataLakeStorageForDevAirline.json  # ADLS connection
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd-pipeline.yml                  # GitHub Actions workflow
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ setup-guide.md                          # Setup instructions
â”‚   â””â”€â”€ deployment-guide.md                     # Deployment steps
â”‚
â””â”€â”€ README.md                                    # This file
```

---

## ğŸš€ Project Setup & Deployment

### **Prerequisites**

- Azure Subscription
- Azure Data Factory (DEV & PROD instances)
- Azure Data Lake Storage Gen2 account
- Azure Synapse Analytics workspace
- GitHub account
- Azure DevOps organization
- Self-hosted agent (local machine)

### **Phase 1: Development Environment Setup**

#### 1. **Create Azure Resources**

```bash
# Resource Group
az group create --name rg-airline-dev --location eastus

# Storage Account (ADLS Gen2)
az storage account create \
  --name airlinedev \
  --resource-group rg-airline-dev \
  --location eastus \
  --sku Standard_LRS \
  --kind StorageV2 \
  --enable-hierarchical-namespace true

# Create containers
az storage container create --name united-airlines --account-name airlinedev

# Data Factory (DEV)
az datafactory create \
  --resource-group rg-airline-dev \
  --name airline-adf-develop
```

#### 2. **Upload Sample Data**

Upload to ADLS `united-airlines/landing-zn/`:
- `airports.csv` - Airport dimension data
- `flights.csv` - Daily flight data

#### 3. **Configure ADF Pipeline**

- Create linked service to ADLS
- Create datasets (airports, flights, processed)
- Create data flow (transformation logic)
- Create pipeline (orchestration)
- Test and validate

### **Phase 2: Azure DevOps Setup**

#### 1. **Create Organization & Project**

```
1. Go to https://dev.azure.com
2. Create Organization: "YourOrgName"
3. Create Project: "Airlines-Data-Pipeline"
4. Create Repository: Import from GitHub or create new
```

#### 2. **Setup Self-Hosted Agent**

```bash
# Download agent
mkdir myagent && cd myagent
wget https://vstsagentpackage.azureedge.net/agent/4.268.0/vsts-agent-osx-x64-4.268.0.tar.gz
tar zxvf vsts-agent-osx-x64-4.268.0.tar.gz

# Configure agent
./config.sh
# Enter: https://dev.azure.com/{your-org}
# Enter: PAT token
# Enter: Agent pool name (Default)
# Enter: Agent name

# Run agent
./run.sh
```

#### 3. **Create Build Pipeline**

```yaml
# azure-pipelines.yml
trigger:
  branches:
    include:
      - main
      - develop

pool:
  name: 'Default'  # Your self-hosted agent pool

steps:
  - task: CopyFiles@2
    inputs:
      SourceFolder: '$(Build.SourcesDirectory)'
      Contents: |
        **/ARMTemplateForFactory.json
        **/ARMTemplateParametersForFactory.json
      TargetFolder: '$(Build.ArtifactStagingDirectory)'
  
  - task: PublishBuildArtifacts@1
    inputs:
      PathtoPublish: '$(Build.ArtifactStagingDirectory)'
      ArtifactName: 'arm-templates'
```

### **Phase 3: CI/CD Release Pipeline**

#### 1. **Create Release Pipeline**

```
1. Go to Pipelines â†’ Releases â†’ New Pipeline
2. Add Artifact: Select your build pipeline
3. Add Stage: "Deploy to PROD"
4. Add Tasks:
   - ARM Template Deployment
   - Configure parameters for PROD environment
```

#### 2. **Configure ARM Deployment**

```json
{
  "factoryName": "airline-adf-prod",
  "AzureDataLakeStorageForDevAirline_accountKey": "$(StorageAccountKey)",
  "AzureDataLakeStorageForDevAirline_properties_typeProperties_url": "https://airlineprod.dfs.core.windows.net/"
}
```

#### 3. **Enable Continuous Deployment**

- Enable CD trigger on artifact
- Set branch filter: `main`
- Every merge to main â†’ auto-deploys to PROD

---

## ğŸ”„ CI/CD Workflow

```
Developer makes changes
        â†“
Commit & Push to GitHub (develop branch)
        â†“
Create Pull Request to main
        â†“
Code Review & Approval
        â†“
Merge to main
        â†“
Azure DevOps Build Pipeline Triggered
        â†“
Build ARM Templates
        â†“
Create Build Artifacts
        â†“
Release Pipeline Triggered (CD)
        â†“
Deploy ARM Templates to PROD ADF
        â†“
Update Pipelines, Datasets, Data Flows
        â†“
Production Deployment Complete âœ…
```

---

## ğŸ“Š Data Flow Details

### **Transformation Steps**

1. **Source: AirportDimdata**
   - Schema: `airport_id, city, state, name`
   - Source: `united-airlines/landing-zn/airports.csv`

2. **Source: DailyFlightsData**
   - Schema: `Carrier, OriginAirportID, DestAirportID, DepDelay, ArrDelay`
   - Source: `united-airlines/landing-zn/flights.csv`

3. **Join: joinOnDeptAirport**
   - Type: Inner Join
   - Condition: `OriginAirportID == airport_id`
   - Result: Flight + Departure Airport details

4. **Select: DeriveDeptAirportDetails**
   - Rename: `city â†’ Depcity`, `state â†’ Depstate`, `name â†’ Depname`
   - Keep: `Carrier, DestAirportID, DepDelay, ArrDelay`

5. **Join: JoinOnArrivalAirport**
   - Type: Inner Join
   - Condition: `DestAirportID == airport_id`
   - Result: Flight + Departure + Arrival Airport details

6. **Select: DeriveArrivalAirport**
   - Rename: `city â†’ Arrcity`, `state â†’ Arrstate`, `name â†’ Arrname`
   - Final Schema: `Carrier, DepDelay, ArrDelay, Depcity, Depstate, Depname, Arrcity, Arrstate, Arrname`

7. **Sink: writeProcessedData**
   - Destination: `united-airlines/processed-data/`
   - Mode: Truncate (full refresh)

---

## ğŸ”§ Configuration

### **Environment Variables**

Create parameter files for each environment:

**DEV:**
```json
{
  "factoryName": "airline-adf-develop",
  "storageAccountUrl": "https://airlinedev.dfs.core.windows.net/",
  "storageAccountKey": "***"
}
```

**PROD:**
```json
{
  "factoryName": "airline-adf-prod",
  "storageAccountUrl": "https://airlineprod.dfs.core.windows.net/",
  "storageAccountKey": "***"
}
```

### **Linked Service Configuration**

```json
{
  "name": "AzureDataLakeStorageForDevAirline",
  "type": "AzureBlobFS",
  "typeProperties": {
    "url": "https://airlinedev.dfs.core.windows.net/",
    "accountKey": {
      "type": "SecureString",
      "value": "***"
    }
  }
}
```

---

## ğŸ“ˆ Monitoring & Alerts

### **ADF Monitoring**

1. **Pipeline Runs**: Monitor execution history
2. **Activity Runs**: Track individual activity status
3. **Data Flow Debug**: Test transformations
4. **Metrics**: Success rate, duration, data volume

### **Logic Apps Integration** (Optional)

```
Pipeline Failure/Success
        â†“
Trigger Logic App
        â†“
Send Email/Teams Notification
        â†“
Log to Monitoring Dashboard
```

---

## ğŸ§ª Testing

### **Unit Testing**

```bash
# Test pipeline with sample data
az datafactory pipeline create-run \
  --resource-group rg-airline-dev \
  --factory-name airline-adf-develop \
  --name airlinepipeline
```

### **Data Validation**

1. Check row counts: Source vs. Processed
2. Validate joins: No data loss
3. Verify schema: All columns present
4. Test edge cases: Empty files, missing airports

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ‘¥ Authors

**Your Name**  
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your Profile](https://linkedin.com/in/yourprofile)

---

## ğŸ™ Acknowledgments

- Microsoft Azure Documentation
- Azure Data Factory Best Practices
- Azure DevOps Community

---

## ğŸ“ Support

For issues and questions:
- Open an issue in this repository
- Contact: your.email@example.com

---

**Last Updated:** February 2026
